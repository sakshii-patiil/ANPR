{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CUDpouPX1jpyypf0YyMIZ3svYejNZwEv",
      "authorship_tag": "ABX9TyMbLH5HcvGGyqDhEdqSYRgs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakshii-patiil/ANPR/blob/main/TensorFlowLite_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "HApsMf7kz5YV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4Zuu8TZOhGB"
      },
      "outputs": [],
      "source": [
        "!pip uninstall Cython -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "eiRUfu0VijyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "YkPkYWbvim_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open('/content/models/research/setup.py', 'w') as f:\n",
        "    s = re.sub('tf-models-official>=2.5.1',\n",
        "               'tf-models-official==2.8.0', s)\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "0YMwQaAuiwRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.3\n",
        "!pip install /content/models/research/\n",
        "!pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "id": "qqdZOmMfi1FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "_oBdQ43Ejyls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"qegCt6JePubFR7ExvlqK\")\n",
        "project = rf.workspace(\"snu-i6ovv\").project(\"license-plate-detector-ogxxg\")\n",
        "dataset = project.version(1).download(\"tensorflow\")"
      ],
      "metadata": {
        "id": "PhdprClwsuSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating TF records"
      ],
      "metadata": {
        "id": "Qx7jz9cgwU7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/Arijit1080/Licence-Plate-Detection-using-TensorFlow-Lite/main/create_tfrecord.py"
      ],
      "metadata": {
        "id": "IN2xUbpbv3uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 create_tfrecord.py --csv_input=/content/License-Plate-Detector-1/train/_annotations.csv --labelmap=labelmap.txt --image_dir=License-Plate-Detector-1/train --output_path=train.tfrecord"
      ],
      "metadata": {
        "id": "_j-LyCT7wLvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 create_tfrecord.py --csv_input=/content/License-Plate-Detector-1/valid/_annotations.csv --labelmap=labelmap.txt --image_dir=License-Plate-Detector-1/valid --output_path=val.tfrecord"
      ],
      "metadata": {
        "id": "5BZDD9Tewn29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_record_fname = '/content/train.tfrecord'\n",
        "val_record_fname = '/content/val.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/labelmap.pbtxt'"
      ],
      "metadata": {
        "id": "84vP49pRxFG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ssd_mobilenet_v2_320x320_coco17_tpu-8'\n",
        "pretrained_checkpoint = 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz'\n",
        "base_pipeline_file = 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config'"
      ],
      "metadata": {
        "id": "waJM_NUfxHnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/models/mymodel/\n",
        "%cd /content/models/mymodel/\n",
        "\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ],
      "metadata": {
        "id": "tmHCwymaxLOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 30000\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "2R18GdNGxb9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_fname = '/content/models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "print('Total classes:', num_classes)"
      ],
      "metadata": {
        "id": "63wKkp3gxkCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration file"
      ],
      "metadata": {
        "id": "ILfn0R5jyLaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "%cd /content/models/mymodel\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    s = re.sub('learning_rate_base: .8','learning_rate_base: .08', s)\n",
        "\n",
        "    s = re.sub('warmup_learning_rate: 0.13333','warmup_learning_rate: .026666', s)\n",
        "\n",
        "    f.write(s)\n"
      ],
      "metadata": {
        "id": "Mxg18HkLxt7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_file = '/content/models/mymodel/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ],
      "metadata": {
        "id": "TABfvISnyQ3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training part"
      ],
      "metadata": {
        "id": "UULioXK_ySRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ],
      "metadata": {
        "id": "XJGFWHTmyVYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export TFLite graph"
      ],
      "metadata": {
        "id": "KKMaSv0fyewU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/custom_model_lite\n",
        "output_directory = '/content/custom_model_lite'\n",
        "\n",
        "last_model_path = '/content/training'\n",
        "\n",
        "!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}"
      ],
      "metadata": {
        "id": "3IgLMqzEyia_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Model (TFLite file)"
      ],
      "metadata": {
        "id": "SDEMmpxEypgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('/content/custom_model_lite/detect.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "X2ISZE_cys8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detect images functions using model"
      ],
      "metadata": {
        "id": "LeS430vBzCVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import importlib.util\n",
        "from tensorflow.lite.python.interpreter import Interpreter\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/results', txt_only=False):\n",
        "\n",
        "  images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n",
        "  with open(lblpath, 'r') as f:\n",
        "      labels = [line.strip() for line in f.readlines()]\n",
        "\n",
        "  interpreter = Interpreter(model_path=modelpath)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  height = input_details[0]['shape'][1]\n",
        "  width = input_details[0]['shape'][2]\n",
        "\n",
        "  float_input = (input_details[0]['dtype'] == np.float32)\n",
        "\n",
        "  input_mean = 127.5\n",
        "  input_std = 127.5\n",
        "\n",
        "  images_to_test = random.sample(images, num_test_images)\n",
        "\n",
        "  for image_path in images_to_test:\n",
        "\n",
        "      image = cv2.imread(image_path)\n",
        "      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      imH, imW, _ = image.shape\n",
        "      image_resized = cv2.resize(image_rgb, (width, height))\n",
        "      input_data = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "      if float_input:\n",
        "          input_data = (np.float32(input_data) - input_mean) / input_std\n",
        "\n",
        "      interpreter.set_tensor(input_details[0]['index'],input_data)\n",
        "      interpreter.invoke()\n",
        "\n",
        "      boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Bounding box coordinates of detected objects\n",
        "      classes = interpreter.get_tensor(output_details[3]['index'])[0] # Class index of detected objects\n",
        "      scores = interpreter.get_tensor(output_details[0]['index'])[0] # Confidence of detected objects\n",
        "\n",
        "      detections = []\n",
        "\n",
        "      for i in range(len(scores)):\n",
        "          if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
        "\n",
        "              ymin = int(max(1,(boxes[i][0] * imH)))\n",
        "              xmin = int(max(1,(boxes[i][1] * imW)))\n",
        "              ymax = int(min(imH,(boxes[i][2] * imH)))\n",
        "              xmax = int(min(imW,(boxes[i][3] * imW)))\n",
        "\n",
        "              cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n",
        "\n",
        "              object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n",
        "              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n",
        "              labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n",
        "              label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
        "              cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n",
        "              cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n",
        "\n",
        "              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
        "\n",
        "\n",
        "      if txt_only == False:\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        plt.figure(figsize=(12,16))\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "\n",
        "      elif txt_only == True:\n",
        "\n",
        "        image_fn = os.path.basename(image_path)\n",
        "        base_fn, ext = os.path.splitext(image_fn)\n",
        "        txt_result_fn = base_fn +'.txt'\n",
        "        txt_savepath = os.path.join(savepath, txt_result_fn)\n",
        "\n",
        "        with open(txt_savepath,'w') as f:\n",
        "            for detection in detections:\n",
        "                f.write('%s %.4f %d %d %d %d\\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "GvaBQ-pqy9tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_IMAGES='/content/License-Plate-Detector-1/test'  #test folder\n",
        "PATH_TO_MODEL='/content/custom_model_lite/detect.tflite'\n",
        "PATH_TO_LABELS='/content/labelmap.txt'\n",
        "min_conf_threshold=0.5\n",
        "images_to_test = 10\n",
        "\n",
        "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)"
      ],
      "metadata": {
        "id": "UaoFO0RJzXNo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}